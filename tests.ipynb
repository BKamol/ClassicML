{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KABabadzhanov\\AppData\\Local\\Temp\\ipykernel_12576\\1662815981.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=14, n_informative=10, noise=15, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=14, n_informative=10, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]\n",
    "df = pd.read_csv('./data/data_banknote_authentication.txt', header=None)\n",
    "df.columns = ['variance', 'skewness', 'curtosis', 'entropy', 'target']\n",
    "X, y = df.iloc[:,:4], df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, value, left=None, right=None):\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Node: ({self.value}), ({self.right}), ({self.left})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTreeClf:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, max_leafs=20, bins=None, criterion='entropy'):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "\n",
    "        self.leafs_cnt = 0\n",
    "        self.root = None\n",
    "        self.bins = bins\n",
    "        self.splitters = None\n",
    "        self.criterion = criterion\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MyTreeClf class: max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}\"\n",
    "\n",
    "    def _get_splitters(self, x):\n",
    "        values = np.array(sorted(x.unique()))\n",
    "        splitters = np.array([(values[i] + values[i+1])/2 for i in range(len(values)-1)])\n",
    "        return splitters\n",
    "    \n",
    "    def _get_splitters_wbins(self, X, y):\n",
    "        self.splitters = {}\n",
    "        if self.bins:\n",
    "            native_splitters = {col: self._get_splitters(X[col]) for col in X.columns}\n",
    "            for col, splitters in native_splitters.items():\n",
    "                if len(splitters) <= self.bins - 1:\n",
    "                    self.splitters[col] = splitters\n",
    "                else:\n",
    "                    hist = np.histogram(X[col], bins=self.bins)[1][1:-1]\n",
    "                    self.splitters[col] = hist\n",
    "\n",
    "    def _entropy(self, col_targ):\n",
    "        p0 = (col_targ.iloc[:, 1] == 0).sum() / (col_targ.shape[0] + 1e-15)\n",
    "        p1 = col_targ.iloc[:, 1].sum() / (col_targ.shape[0] + 1e-15)\n",
    "        S = -p0*np.log2(p0+1e-15) - p1*np.log2(p1+1e-15)\n",
    "        return S\n",
    "\n",
    "    def _gini(self, col_targ):\n",
    "        p0 = (col_targ.iloc[:, 1] == 0).sum() / (col_targ.shape[0] + 1e-15)\n",
    "        p1 = col_targ.iloc[:, 1].sum() / (col_targ.shape[0] + 1e-15)\n",
    "        G = 1 - p0**2 - p1**2\n",
    "        return G\n",
    "\n",
    "    def _get_ig(self, x, y, split):\n",
    "        col_targ = pd.concat([x, y], axis=1)\n",
    "\n",
    "        left_sub = col_targ.loc[col_targ[x.name] <= split, :]\n",
    "        right_sub = col_targ.loc[col_targ[x.name] > split, :]\n",
    "\n",
    "        if self.criterion == 'gini':\n",
    "            Gp = self._gini(col_targ)\n",
    "            Gl, Gr = self._gini(left_sub), self._gini(right_sub)\n",
    "            IG = Gp - left_sub.shape[0]/(col_targ.shape[0] + 1e-15)*Gl - right_sub.shape[0]/(col_targ.shape[0] + 1e-15)*Gr\n",
    "        else:\n",
    "            S0 = self._entropy(col_targ)\n",
    "            S1, S2 = self._entropy(left_sub), self._entropy(right_sub)\n",
    "            IG = S0 - left_sub.shape[0]/(col_targ.shape[0] + 1e-15)*S1 - right_sub.shape[0]/(col_targ.shape[0] + 1e-15)*S2\n",
    "        return IG\n",
    "        \n",
    "\n",
    "    def _get_best_split(self, X, y):\n",
    "        cols = X.columns\n",
    "        if self.bins is None:\n",
    "            splitters = {col: self._get_splitters(X[col]) for col in cols}\n",
    "        else:\n",
    "            splitters = self.splitters\n",
    "        best_col = None\n",
    "        best_split = None\n",
    "        best_ig = 0\n",
    "        for col, splits in splitters.items():\n",
    "            x = X[col]\n",
    "            igs = np.array([self._get_ig(x, y, split) for split in splits])\n",
    "            max_idx = igs.argmax()\n",
    "            max_ig, max_split = igs[max_idx], splits[max_idx]\n",
    "            if max_ig > best_ig:\n",
    "                best_col = col\n",
    "                best_split = max_split\n",
    "                best_ig = max_ig\n",
    "        \n",
    "        return best_col, best_split, best_ig\n",
    "\n",
    "    def is_leaf(self, data, depth):\n",
    "        return (all(data.iloc[:, -1] == 1)) or\\\n",
    "               (all(data.iloc[:, -1] == 0)) or\\\n",
    "               (depth >= self.max_depth-1) or\\\n",
    "               (data.shape[0] < self.min_samples_split) or\\\n",
    "               (self.leafs_cnt >= self.max_leafs-1)\n",
    "\n",
    "    \n",
    "    def _fit(self, X, y, depth=0):\n",
    "        best_col, best_split, best_ig = self._get_best_split(X, y)\n",
    "        root = Node((best_col, best_split))\n",
    "        #print(best_col, best_split, best_ig)\n",
    "        col_targ = pd.concat([X, y], axis=1)\n",
    "\n",
    "        if (best_col is None):\n",
    "            value = col_targ.iloc[:, -1].sum() / col_targ.shape[0]\n",
    "            return Node(('leaf', value))\n",
    "\n",
    "        left_sub = col_targ.loc[col_targ[best_col] <= best_split, :]\n",
    "        right_sub = col_targ.loc[col_targ[best_col] > best_split, :]\n",
    "\n",
    "        if self.is_leaf(left_sub, depth):\n",
    "            value = left_sub.iloc[:, -1].sum() / (left_sub.shape[0] + 1e-15)\n",
    "            root.left = Node(('left', value))\n",
    "            self.leafs_cnt += 1\n",
    "        else:\n",
    "            X, y = left_sub.drop(left_sub.columns[-1], axis=1), left_sub.iloc[:, -1]\n",
    "            root.left = self._fit(X, y, depth+1)\n",
    "\n",
    "        if self.is_leaf(right_sub, depth):\n",
    "            value = right_sub.iloc[:, -1].sum() / (right_sub.shape[0] + 1e-15)\n",
    "            root.right = Node(('right', value))\n",
    "            self.leafs_cnt += 1\n",
    "        else:\n",
    "            X, y = right_sub.drop(right_sub.columns[-1], axis=1), right_sub.iloc[:, -1]\n",
    "            root.right = self._fit(X, y, depth+1)\n",
    "        return root\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._get_splitters_wbins(X, y)\n",
    "        self.root = self._fit(X, y)\n",
    "\n",
    "    \n",
    "    def _predict_proba(self, x, root):\n",
    "        if (root.right is None and root.left is None):\n",
    "            return root.value[1]\n",
    "        \n",
    "        feat, split = root.value\n",
    "        if x[feat] <= split:\n",
    "            return self._predict_proba(x, root.left)\n",
    "        else:\n",
    "            return self._predict_proba(x, root.right)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_pred_logits = np.array([self._predict_proba(X.iloc[i, :], self.root) for i in range(X.shape[0])])\n",
    "        return y_pred_logits\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = (self.predict_proba(X) > 0.5).astype(int)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def _print_tree(self, root, intend):\n",
    "        if (root is None):\n",
    "            return None\n",
    "        \n",
    "        feat, split = root.value\n",
    "        if (root.left is None and root.right is None):\n",
    "            print('  '*intend, end='')\n",
    "            print(f\"{feat} = {split}\")\n",
    "        else:\n",
    "            print('  '*intend, end='')\n",
    "            print(f\"{feat} > {split}\")\n",
    "\n",
    "        self._print_tree(root.left, intend+1)\n",
    "        self._print_tree(root.right, intend+1)\n",
    "\n",
    "    def print_tree(self):\n",
    "        self._print_tree(self.root, 0)\n",
    "\n",
    "    def _sum_leafs(self, root):\n",
    "        if (root is None):\n",
    "            return 0\n",
    "        if (root.left is None and root.right is None):\n",
    "            return root.value[1]\n",
    "        return self._sum_leafs(root.left) + self._sum_leafs(root.right)\n",
    "    \n",
    "    def sum_leafs(self):\n",
    "        return self._sum_leafs(self.root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=14, n_informative=10, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]\n",
    "df = pd.read_csv('./data/data_banknote_authentication.txt', header=None)\n",
    "df.columns = ['variance', 'skewness', 'curtosis', 'entropy', 'target']\n",
    "X, y = df.iloc[:,:4], df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1367    1\n",
       "1368    1\n",
       "1369    1\n",
       "1370    1\n",
       "1371    1\n",
       "Name: target, Length: 1372, dtype: int64"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_tag = pd.concat([X, y], axis=1)\n",
    "col_tag.loc[:, y.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "12.412269\n",
      "variance > -0.10864999999999903\n",
      "  skewness > 8.497483333333335\n",
      "    skewness > 4.043366666666667\n",
      "      curtosis > 6.32065\n",
      "        curtosis > 2.4517333333333333\n",
      "          left = 1.0\n",
      "          entropy > -1.2163999999999993\n",
      "            left = 0.0\n",
      "            skewness > -0.41075000000000017\n",
      "              left = 1.0\n",
      "              right = 0.8333333333333333\n",
      "        skewness > -4.864866666666666\n",
      "          entropy > -1.2163999999999993\n",
      "            variance > -2.4197999999999995\n",
      "              left = 1.0\n",
      "              right = 0.7999999999999998\n",
      "            right = 1.0\n",
      "          skewness > -0.41075000000000017\n",
      "            left = 0.33333333333333326\n",
      "            right = 0.0\n",
      "      variance > -2.4197999999999995\n",
      "        left = 1.0\n",
      "        right = 0.0\n",
      "    variance > -4.73095\n",
      "      left = 0.9999999999999999\n",
      "      right = 0.0\n",
      "  variance > 2.2025000000000006\n",
      "    curtosis > -1.4171833333333335\n",
      "      skewness > 8.497483333333335\n",
      "        skewness > 4.043366666666667\n",
      "          left = 1.0\n",
      "          entropy > -4.882299999999999\n",
      "            left = 0.9999999999999998\n",
      "            right = 0.47058823529411764\n",
      "        right = 0.0\n",
      "      entropy > 0.6165500000000002\n",
      "        skewness > 4.043366666666667\n",
      "          curtosis > 2.4517333333333333\n",
      "            skewness > -0.41075000000000017\n",
      "              left = 0.7499999999999999\n",
      "              leaf = 0.3548387096774194\n",
      "            right = 0.0\n",
      "          right = 0.0\n",
      "        curtosis > 2.4517333333333333\n",
      "          left = 0.7368421052631579\n",
      "          right = 0.0\n",
      "    entropy > -1.2163999999999993\n",
      "      skewness > 8.497483333333335\n",
      "        curtosis > -1.4171833333333335\n",
      "          left = 0.1333333333333333\n",
      "          right = 0.0\n",
      "        right = 0.0\n",
      "      right = 0.0\n"
     ]
    }
   ],
   "source": [
    "my_tree = MyTreeClf(15, 20, 30, 6, 'gini')\n",
    "my_tree.fit(X, y)\n",
    "print(my_tree.leafs_cnt)\n",
    "print(round(my_tree.sum_leafs(), 6))\n",
    "my_tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8440233236151603"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_logits = my_tree.predict_proba(X)\n",
    "y_pred = my_tree.predict(X)\n",
    "(y_pred == y).sum() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variance    -7.0421\n",
       "skewness   -13.7731\n",
       "curtosis    -5.2861\n",
       "entropy     -8.5482\n",
       "target       0.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_tag.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
